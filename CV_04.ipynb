{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d01a1655",
   "metadata": {
    "id": "d01a1655"
   },
   "source": [
    "# 1. Exercise of saving model parameter etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c65cd",
   "metadata": {
    "id": "047c65cd"
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb9095",
   "metadata": {
    "id": "2eeb9095"
   },
   "outputs": [],
   "source": [
    "# MNIST data download\n",
    "# the below codes don't work\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_set(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# alternative\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "y_train, y_test = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)\n",
    "\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(60000).batch(50)\n",
    "train_data_iter = iter(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2070e1b",
   "metadata": {
    "id": "e2070e1b"
   },
   "source": [
    "## Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52746f76",
   "metadata": {
    "id": "52746f76"
   },
   "outputs": [],
   "source": [
    "# define CNN model\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # the first Convolution layer\n",
    "        # apply 32 filters with 5x5 Kernel size\n",
    "        self.conv_layer_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=1, padding='same', activation='relu')\n",
    "        self.pool_layer_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)\n",
    "        \n",
    "        # the second Convolution layer\n",
    "        # apply 64 filters with 5x5 Kernel size\n",
    "        self.conv_layer_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=1, padding='same', activation='relu')\n",
    "        self.pool_layer_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)\n",
    "        \n",
    "        #Fully connected Layer\n",
    "        # Change 7x7 64 activation maps to 1024 features\n",
    "        self.flatten_layer = tf.keras.layers.Flatten()\n",
    "        self.fc_layer_1 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "        \n",
    "        # Output Layer\n",
    "        # Change 1024 features as 10 classes by one-hot encodding\n",
    "        self.output_layer = tf.keras.layers.Dense(10, activation=None)\n",
    "        \n",
    "    def call(self,x):\n",
    "        # reshape MNIST data as 3 dims\n",
    "        x_image = tf.reshape(x, [-1,28,28,1])\n",
    "        # 28x28x1 -> 28x28x32\n",
    "        h_conv1 = self.conv_layer_1(x_image)\n",
    "        # 28x28x32 -> 14x14x32\n",
    "        h_pool1 = self.pool_layer_1(h_conv1)\n",
    "        # 14x14x32 -> 14x14x64\n",
    "        h_conv2 = self.conv_layer_2(h_pool1)\n",
    "        # 14x14x64 -> 7x7x64\n",
    "        h_pool2 = self.pool_layer_2(h_conv2)\n",
    "        # 7x7x64(3136) -> 1024\n",
    "        h_pool2_flat = self.flatten_layer(h_pool2)\n",
    "        h_fc1 = self.fc_layer_1(h_pool2_flat)\n",
    "        # 1024 -> 10\n",
    "        logits = self.output_layer(h_fc1)\n",
    "        y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "        return y_pred, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc82fd9",
   "metadata": {
    "id": "edc82fd9"
   },
   "outputs": [],
   "source": [
    "# difine cross-entropy loss function\n",
    "def cross_entropy_loss(logits, y):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f6218",
   "metadata": {
    "id": "305f6218"
   },
   "outputs": [],
   "source": [
    "# define optimizer for optimization\n",
    "optimizer = tf.optimizers.Adam(1e-4)\n",
    "\n",
    "# function for optimization\n",
    "def train_step(model, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred, logits = model(x)\n",
    "        loss = cross_entropy_loss(logits, y)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "# function for printing model's accuracy\n",
    "def compute_accuracy(y_pred, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f57341",
   "metadata": {
    "id": "63f57341",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# declare model\n",
    "CNN_model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378d5f6",
   "metadata": {
    "id": "b378d5f6"
   },
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55e93c",
   "metadata": {
    "id": "7a55e93c"
   },
   "outputs": [],
   "source": [
    "# saving parameter using tf.train.CheckpointManager\n",
    "\n",
    "SAVER_DIR = \"./model\"\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(0), model = CNN_model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, directory=SAVER_DIR ,max_to_keep=5)\n",
    "latest_ckpt = tf.train.latest_checkpoint(SAVER_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c13b04",
   "metadata": {
    "id": "31c13b04"
   },
   "source": [
    "## Restore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc486a81",
   "metadata": {
    "id": "fc486a81",
    "outputId": "825ac1c1-a593-4a56-f163-f2a96cb23f8b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Restored): 0.982800\n"
     ]
    }
   ],
   "source": [
    "# if there is a saved model and parameter then restore it\n",
    "# and by using it print precision of test dataset and quit the program\n",
    "if latest_ckpt:\n",
    "    ckpt.restore(latest_ckpt)\n",
    "    print(\"Accuracy (Restored): %f\" % compute_accuracy(CNN_model(x_test)[0], y_test))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb2ac7",
   "metadata": {
    "id": "22cb2ac7",
    "outputId": "fa23bf7b-6922-4b2e-a7cf-dcae3cb2caec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1700, Precision of training data: 1.000000\n",
      "Epoch: 1800, Precision of training data: 0.960000\n",
      "Epoch: 1900, Precision of training data: 0.980000\n",
      "Epoch: 2000, Precision of training data: 0.940000\n",
      "Epoch: 2100, Precision of training data: 0.960000\n",
      "Epoch: 2200, Precision of training data: 0.980000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Precision of training data: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mstep, train_accuracy))\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# update parameter using optimizer\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCNN_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     ckpt\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39massign_add(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# if training is end, then print the precision\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, x, y)\u001b[0m\n\u001b[0;32m      7\u001b[0m     y_pred, logits \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m cross_entropy_loss(logits, y)\n\u001b[1;32m----> 9\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1063\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1057\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1058\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1059\u001b[0m           output_gradients))\n\u001b[0;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1061\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1063\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1072\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:146\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    144\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py:592\u001b[0m, in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    573\u001b[0m shape_0, shape_1 \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape_n([op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# to use the nn_ops functions, we would have to convert `padding` and\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;66;03m# in Eager mode.\u001b[39;00m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    582\u001b[0m     gen_nn_ops\u001b[38;5;241m.\u001b[39mconv2d_backprop_input(\n\u001b[0;32m    583\u001b[0m         shape_0,\n\u001b[0;32m    584\u001b[0m         op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    585\u001b[0m         grad,\n\u001b[0;32m    586\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[0;32m    587\u001b[0m         strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[0;32m    588\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    589\u001b[0m         explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[0;32m    590\u001b[0m         use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[0;32m    591\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mdata_format),\n\u001b[1;32m--> 592\u001b[0m     \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_backprop_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplicit_paddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1369\u001b[0m, in \u001b[0;36mconv2d_backprop_filter\u001b[1;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   1368\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1369\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv2DBackpropFilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_backprop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrides\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_cudnn_on_gpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpadding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplicit_paddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdilations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   1375\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimize for 10000 step\n",
    "while int(ckpt.step) < (10000 + 1):\n",
    "    # load the 50 MNIST data at a time\n",
    "    batch_x, batch_y = next(train_data_iter)\n",
    "    \n",
    "    # print accuracy of train dataset in each 100 step, then save parameter using tf.train.CheckpointManager\n",
    "    if ckpt.step % 100 == 0:\n",
    "        ckpt_manager.save(checkpoint_number=ckpt.step)\n",
    "        train_accuracy = compute_accuracy(CNN_model(batch_x)[0], batch_y)\n",
    "        print(\"Epoch: %d, Accuracy of training data: %f\" % (ckpt.step, train_accuracy))\n",
    "        \n",
    "    # update parameter using optimizer\n",
    "    train_step(CNN_model, batch_x, batch_y)\n",
    "    ckpt.step.assign_add(1)\n",
    "\n",
    "# if training is end, then print the accuracy\n",
    "print(\"Accuracy (Restored): %f\" % compute_accuracy(CNN_model(x_test)[0], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbf672",
   "metadata": {
    "id": "b2cbf672"
   },
   "source": [
    "# 2. Exercise of using TenserBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767840bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "767840bd",
    "outputId": "e39bd148-9eb4-4c4d-b327-8a7d68f7e290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# TensorBoard 예제\n",
    "# Convolutional Neural Networks(CNN)을 이용한 MNIST 분류기(Classifier) - Keras API를 이용한 구현\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# MNIST 데이터를 다운로드 합니다.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# 이미지들을 float32 데이터 타입으로 변경합니다.\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "# 28*28 형태의 이미지를 784차원으로 flattening 합니다.\n",
    "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])\n",
    "# [0, 255] 사이의 값을 [0, 1]사이의 값으로 Normalize합니다.\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "# 레이블 데이터에 one-hot encoding을 적용합니다.\n",
    "y_train, y_test = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)\n",
    "\n",
    "# tf.data API를 이용해서 데이터를 섞고 batch 형태로 가져옵니다.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(60000).batch(50)\n",
    "train_data_iter = iter(train_data)\n",
    "\n",
    "# tf.keras.Model을 이용해서 CNN 모델을 정의합니다.\n",
    "class CNN(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    # 첫번째 Convolution Layer\n",
    "    # 5x5 Kernel Size를 가진 32개의 Filter를 적용합니다.\n",
    "    self.conv_layer_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=1, padding='same', activation='relu')\n",
    "    self.pool_layer_1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)\n",
    "\n",
    "    # 두번째 Convolutional Layer\n",
    "    # 5x5 Kernel Size를 가진 64개의 Filter를 적용합니다.\n",
    "    self.conv_layer_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=1, padding='same', activation='relu')\n",
    "    self.pool_layer_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    # 7x7 크기를 가진 64개의 activation map을 1024개의 특징들로 변환합니다.\n",
    "    self.flatten_layer = tf.keras.layers.Flatten()\n",
    "    self.fc_layer_1 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "\n",
    "    # Output Layer\n",
    "    # 1024개의 특징들(feature)을 10개의 클래스-one-hot encoding으로 표현된 숫자 0~9-로 변환합니다.\n",
    "    self.output_layer = tf.keras.layers.Dense(10, activation=None)\n",
    "\n",
    "  def call(self, x):\n",
    "    # MNIST 데이터를 3차원 형태로 reshape합니다. MNIST 데이터는 grayscale 이미지기 때문에 3번째차원(컬러채널)의 값은 1입니다.\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    # 28x28x1 -> 28x28x32\n",
    "    h_conv1 = self.conv_layer_1(x_image)\n",
    "    # 28x28x32 -> 14x14x32\n",
    "    h_pool1 = self.pool_layer_1(h_conv1)\n",
    "    # 14x14x32 -> 14x14x64\n",
    "    h_conv2 = self.conv_layer_2(h_pool1)\n",
    "    # 14x14x64 -> 7x7x64\n",
    "    h_pool2 = self.pool_layer_2(h_conv2)\n",
    "    # 7x7x64(3136) -> 1024\n",
    "    h_pool2_flat = self.flatten_layer(h_pool2)\n",
    "    h_fc1 = self.fc_layer_1(h_pool2_flat)\n",
    "    # 1024 -> 10\n",
    "    logits = self.output_layer(h_fc1)\n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "    return y_pred, logits\n",
    "\n",
    "# cross-entropy 손실 함수를 정의합니다.\n",
    "@tf.function\n",
    "def cross_entropy_loss(logits, y):\n",
    "  return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "# 최적화를 위한 Adam 옵티마이저를 정의합니다.\n",
    "optimizer = tf.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048804d",
   "metadata": {
    "id": "8048804d"
   },
   "source": [
    "## Code for TensofBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5f41fe3",
   "metadata": {
    "id": "d5f41fe3"
   },
   "outputs": [],
   "source": [
    "# Set the directory of folder for summary info. and delcare FIlewriter\n",
    "train_summary_writer = tf.summary.create_file_writer('./tensorboard_log/train')\n",
    "test_summary_writer = tf.summary.create_file_writer('./tesnsorboard_log/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b17823c0",
   "metadata": {
    "id": "b17823c0"
   },
   "outputs": [],
   "source": [
    "# function for optimization\n",
    "def train_step(model, x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred, logits = model(x)\n",
    "        loss = cross_entropy_loss(logits, y)\n",
    "    # save tf.summary.sclar, tf.summary.image tensor log at each step\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', loss, step=optimizer.iterations)\n",
    "        x_image = tf.reshape(x, [-1,28,28,1])\n",
    "        tf.summary.image('training image', x_image, max_outputs=10, step=optimizer.iterations)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "# function for printing accuracy\n",
    "def compute_accuracy(y_pred, y, summary_writer):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('accuracy', accuracy, step=optimizer.iterations)\n",
    "        \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67746a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Networks(CNN) 모델을 선언합니다.\n",
    "CNN_model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing for 10000 steps\n",
    "for i in range(10000):\n",
    "    # call 50 MNIST data\n",
    "    batch_x, batch_y = next(train_data_iter)\n",
    "    \n",
    "    # print accuracy at each 100 steps\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = compute_accuracy(CNN_model(batch_x)[0], batch_y, train_summary_writer)\n",
    "        print(\"Epoch: %d, Training Accuracy: %f\" % (i, train_accuracy))\n",
    "        \n",
    "    # updating parameter using optimizer\n",
    "    train_step(CNN_model, batch_x, batch_y)\n",
    "    \n",
    "#print Accuracy after fininshed trining\n",
    "print(\"Accuracy: %f\" % compute_accuracy(CNN_model(x_test)[0], y_test, test_summary_writer))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
